{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50ef9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model = \"models/model_checkpoint_1b.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b31e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "base_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "model = torch.load(input_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e967fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_directory = 'dataset/product_images/test/'\n",
    "text_file_location = 'dataset/product_brands_test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a81a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(text_file_location, 'r') as text_file:\n",
    "    input_text = []\n",
    "    for line in text_file:\n",
    "      json_obj = json.loads(line)\n",
    "      input_text.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd30f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = []\n",
    "text_list = []\n",
    "\n",
    "for item in input_text:\n",
    "  image_path = images_directory + item[\"image_path\"]\n",
    "  image_path_list.append(image_path)\n",
    "\n",
    "  title = item['product_title']\n",
    "  text_list.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae87bdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "print(len(image_path_list))\n",
    "print(len(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd603ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class image_title_dataset:\n",
    "  def __init__(self, image_path_list, text_list):\n",
    "    self.image_path = image_path_list\n",
    "    self.title = text_list\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.title)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = preprocess(Image.open(self.image_path[idx]))\n",
    "    title = self.title[idx]\n",
    "    return image, title\n",
    "\n",
    "dataset = image_title_dataset(image_path_list, text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed6d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = [\"Ray-Ban\", \"Carrera\", \"Gucci\", \"Versace\", \"Prada\", \"Tommy Hilfiger\", \"Lacoste\", \"U.S. Polo Assn.\", \"DKNY\", \"Polo Ralph Lauren\", \"Nike\", \"Adidas\", \"Puma\", \"Calvin Klein\", \"Reebok\", \"Under Armour\", \"Brooks Brothers\", \"Haimont\", \"ASICS\", \"Saucony\", \"FitVille\", \"Brooks\", \"Skechers\", \"Red Tape\", \"Little Donkey Andy\", \"33,000ft\", \"Columbia\", \"Carhartt\", \"MAGCOMSEN\", \"The North Face\", \"Darn Tough\", \"VRD\", \"G Gradual\", \"Fila\", \"BROKIG\", \"Champion\", \"NORTHYARD\", \"Mizuno\", \"Hurley\", \"Timberland\"]\n",
    "\n",
    "templates = [\n",
    "    'the brand is {}.',\n",
    "    'the manufacturer is {}.',\n",
    "    'the item is made by {}.',\n",
    "    'the product is manufactured by {}.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2ae2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9e1b3a982340c18178d02d63a96fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def zeroshot_weight_calculator(classification_list, templates):\n",
    "    with torch.no_grad():\n",
    "        weights = []\n",
    "        for element in tqdm(classification_list):\n",
    "            texts = [template.format(element) for template in templates]\n",
    "            texts = clip.tokenize(texts)\n",
    "            text_embeddings = model.encode_text(texts)\n",
    "            text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "            text_embedding = text_embeddings.mean(dim=0)\n",
    "            text_embedding /= text_embedding.norm()\n",
    "            weights.append(text_embedding)\n",
    "        nn_weights = torch.stack(weights, dim=1)\n",
    "    return nn_weights\n",
    "\n",
    "zeroshot_brand_weights = zeroshot_weight_calculator(brands, templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be87fb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 40])\n"
     ]
    }
   ],
   "source": [
    "print(zeroshot_brand_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc83f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    target = torch.tensor(target)    \n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd85f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff71453c49e4b5687f09bd0e6def751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 22.38\n",
      "Top-5 accuracy: 51.90\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    top1, top5, n = 0., 0., 0.\n",
    "    \n",
    "    for i, (images, target) in enumerate(tqdm(dataset)):\n",
    "        \n",
    "        image = []\n",
    "        image.append(images)\n",
    "        image = torch.tensor(np.stack(image))\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        logits = 100. * image_features @ zeroshot_brand_weights\n",
    "        target_index = brands.index(target)\n",
    "        \n",
    "        acc1, acc5 = accuracy(logits, target_index, topk=(1,5))\n",
    "        top1 += acc1\n",
    "        top5 += acc5        \n",
    "        n += image.size(0)        \n",
    "        \n",
    "top1 = (top1 / n) * 100\n",
    "top5 = (top5 / n) * 100 \n",
    "\n",
    "print(f\"Top-1 accuracy: {top1:.2f}\")\n",
    "print(f\"Top-5 accuracy: {top5:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf9184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
